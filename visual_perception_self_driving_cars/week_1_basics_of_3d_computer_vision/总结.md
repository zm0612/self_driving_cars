# 总结

## 1.课程内容总结

### 针孔相机

在这一周的课程中，首先介绍了相机传感器，介绍了小孔成像模型。这里需要注意相机坐标系的原点是在相机的光心处，也就是镜片的中心位置。

### 相机模型

然后对相机的模型进行了建模，对空间中的一个点，将其投影到相机中，其满足以下模型：

**World -> Camera**
$$
O_{camera} = [R|t]O_{world}
$$
**Camera -> Image**
$$
O_{image} = 
\left[
\begin{matrix}
f &0 &u_0 \\
0 & f & v_0 \\
0&0&1
\end{matrix}
\right]
O_{camera}= KO_{camera}
$$
 

令：$P= K[R|t]$

### 相机标定

当有了多对图像点和空间点的对应关系之后，我们将其带入投影模型之中，然后通过最小二乘法求解出矩阵$P$，对$P$矩阵进行分解就可以获得$K$、$R$、$t$

### 双目相机还原深度

深度相机模型比较简单，通过简单的相似三角形就可以获得像素点的深度信息。这里的关键就是求解两个图像的视差图(Disparity Image)，计算视差图主要思路就像图像的特征点匹配。有了视差图对图像进行反投影就可以获得对应像素点的深度信息。

### Cross-Correlation(互相关)和Convolution(卷积)

Cross-Correlation和Convolution是非常相近的两个概念，但是它们还是有一些相似的，互相关操作其实就是我们常说的滤波操作。而卷积操作则是将滤波的核进行上下和左右翻转，然后再进行互相关操作。

这样做将带来一个巨大的好处，就是卷积操作可以满足结合律，但是互相关操作不满足，也就是下式：
$$
H*(F*I) = (H*F)*I
$$
这样将带来一个巨大的好处，就是当需要对图像进行多步的滤波操作的时候，可以先计算滤波的卷积操作。

Cross-Correlation操作可以用来做模板匹配，如果两个图像块非常相似，那么它们通过互相关操作之后将得到非常高响应值。

## 2. 课程作业总结

这一节提到很多的算法和操作，实际上他们还是挺复杂，但幸运的是他们都被Opencv进行了实现，因此只需要调库即可。

**自动驾驶场景下，依赖双目传感器检测障碍物的pipe line**：

- 首先计算视差图，得到左目和右目每个图像像素的视差；
- 然后通过相机的内参对像素点反投影获得每个深度信息；
- 将目标检测的得到的bounding box应用到深度图中，得到该目标距离相机的最近距离。

这里将用到的库函数进行整理和总结：

**视差图的计算**

```python
cv2.StereoSGBM_create(
        minDisparity=min_disparity,
        numDisparities=num_disparities,
        blockSize=block_size,
        P1=8 * 3 * window_size ** 2,
        P2=32 * 3 * window_size ** 2,
        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
 )

  cv2.StereoBM_create(
         numDisparities=num_disparities,
         blockSize=block_size
  )
    
```

**分解投影矩阵**

```python
cv2.decomposeProjectionMatrix(p)
```

**模板匹配**

```python
cv2.matchTemplate(image, obstacle_image, method=cv2.TM_CCOEFF)
```

